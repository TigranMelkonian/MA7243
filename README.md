# MA7243
Course Project

Real-time Video-based vehicle speed estimation is a foundational component in constructing the perception, planning, and control architectures of autonomous driving systems. In this paper I present two monocular video-based vehicle speed estimation systems based on state of the art deep CNN architectures, Nvidia and FlowNetS. My goal is to train and evaluate the performance of both deep CNN architectures and prove that FlowNetS, a CNN specifically architected for learning optical flow, is better suited to learn monocular dashcam video feature motion and more accurately predict vehicle speed estimates when compared to the simpler, baseline Nvidia architecture. If this is the case, then the quality and complexity of a deep CNN responsible for learning optical flow may have a significant influence on vehicle speed prediction performance.
